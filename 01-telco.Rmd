# Telecommunication

```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  comment = "#>",
  echo = TRUE
)

# scientific notation
options(scipen = 9999)
```

```{r message=F, warning=F, echo=FALSE}
library(tidyverse)
library(rsample)
library(MLmetrics)
library(inspectdf)
library(caret)
```


## Customer Churn Prediction

### Background

Customer Churn didefinisikan sebagai kecenderungan pelanggan untuk berhenti melakukan interaksi dengan sebuah perusahaan. Perusahaan telekomunikasi memiliki kebutuhan untuk mengetahui customer yang akan berhenti berlangganan atau tidak, karena biaya mempertahankan pelanggan yang sudah ada jauh lebih sedikit dibandingkan memperoleh pelanggan baru. Perusahaan biasanya mendefinisikan 2 tipe customer churn, yaitu `voluntary churn` dan `involuntary churn`. `Voluntary churn` merupakan pelanggan yang sengaja berhenti dan beralih ke perusahaan lain, sedangkan `involuntary churn` merupakan pelanggan yang berhenti karena perpindahan lokasi, kematian, atau alasan lain yang sulit dikontrol. Analisis `voluntary churn` tentunya tidak sulit untuk mempelajari karakteristik pelanggan yang dapat dilihat dari data profil pelanggan. Permasalah diatas dapat dijawab dengan membuat model prediksi customer churn. Harapannya dengan adanya model prediksi customer churn, dapat mempermudah pihak perusahaan telekomunikasi untuk memperoleh informasi mengenai pelanggan yang berpeluang besar untuk churn.



### Modelling Analysis

#### Import Data

Data yang digunakan merupakan data profil pelanggan perusahaan telekomunikasi yang diperoleh dar [link berikut.](https://www.kaggle.com/blastchar/telco-customer-churn) Data tersebut berisikan 7043 observasi dengan 21 kolom. Target variabel pada data ini adalah `Churn`, kita akan memprediksi apakah pelanggan akan berhenti berlangganan produk atau akan tetep berlangganan.

```{r}
customer <- read.csv("assets/01-telco/WA_Fn-UseC_-Telco-Customer-Churn.csv")
head(customer)
```

Berikut ini merupakan deskripsi untuk setiap variabel:

* `CustomerID`: Customer ID
* `Gender`: Gender pelanggan yaitu Female dan Male
* `SeniorCitizen`: Apakah pelanggan merupakan senio citizen (0: No, 1: Yes)
* `Partner`: Apakah pelanggan memiliki partner atau tidak (Yes, No)
* `Dependents`: Apakah pelanggan memiliki tanggungan atau tidak (Yes, No)
* `Tenure`: Jumlah bulan dalam menggunakan produk perusahaan
* `MultipleLines`: Apakah pelanggan memiliki banyak saluran atau tidak (Yes, No, No phone service)
* `OnlineSecurity`: Apakah pelanggan memiliki keamanan online atau tidak 
* `OnlineBackup`: Apakah pelanggan memiliki cadangan online atau tidak
* `DeviceProtection`: Apakah pelanggan memiliki perlindungan perangkat atau tidak
* `TechSupport`: Apakah pelanggan memiliki dukungan teknis atau tidak
* `StreamingTV`: Apakah pelanggan berlangganan TV streaming atau tidak
* `StreamingMovies`: Apakah pelanggan berlangganan movies streaming atau tidak
* `Contract`: Ketentuan kontrak berlangganan (Month-to-month, One year, Two year)
* `PaperlessBilling`: Apakah pelanggan memiliki tagihan tanpa kertas atau tidak (Yes, No)
* `PaymentMethod`: Metode pembayaran (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))
* `MonthlyCharges`: Jumlah pembayaran yang dilakukan setiap bulan
* `TotalCharges`: Jumlah total yang dibebankan oleh pelanggan
* `Churn`: Apakah pelanggan Churn atau tidak (Yes or No)

#### Exploratory Data

Sebelum eksplorasi lebih lanjut, perlu diketahui kelengkapan data yang dimiliki:
```{r}
colSums(is.na(customer))
```

Dari 7043 observasi ternyata terdapat `missing values` sebanyak 11 observasi pada kolom `TotalCharges`. Karena jumlah `missing values` cukup sedikit kita dapat membuat observasi tersebut. Selain itu, perlu kita buang variabel yang tidak dibutuhkan pada pemodelan yaitu `customerID` dan juga sesuaikan tipe data yang seharusnya.
```{r}
customer <- customer %>% 
            select(-customerID) %>% 
            na.omit() %>% 
            mutate(SeniorCitizen = as.factor(SeniorCitizen)) 
```

Untuk mengetahui proporsi kelas pada setiap variable kategori, kita dapat menggunakan function `inspect_cat` dari package `inspectdf` seperti berikut:
```{r}
customer %>% inspect_cat() %>% show_plot()
```

Dari hasil plot diatas dapat diketahui proporsi kelas untuk target variabel cenderung lebih banyak dikategori `No` namun masih seimbang. Sedangkan untuk variabel lainnya untuk proporsi setiap level nya mayoritas seimbang.

Berikutnya kita dapat eksplorasi persebaran untuk variabel data numerik dengan function `inspect_num` dari package `inspectdf` seperti berikut:
```{r}
customer %>% inspect_num() %>% show_plot()
```

Dari ketiga variabel numerik yang dimiliki, persebaran data cukup beragam untuk setiap nilai.

#### Modelling

Sebelum masuk ke tahap modelling, kita perlu membagi data menjadi `data_train` dan `data_test` dengan proporsi 80:20.
```{r}
set.seed(100)
idx <- initial_split(data = customer,prop = 0.8,strata = Churn)
data_train <- training(idx)
data_test <- testing(idx)
```

Berikutnya bentuk model random forest menggunakan package `caret`, tentukan banyaknya cross validation dan repetition pada model dan juga target variabel dan prediktor yang digunakan.
```{r}
set.seed(100)
ctrl <- trainControl(method="repeatedcv", number=5, repeats=3)
# model_forest <- train(Churn ~ ., data=data_train, method="rf", trControl = ctrl)
```

import model yang sudah dijalankan pada chunk sebelumnya menggunakan `readRDS`.
```{r}
#saveRDS(model_forest,"assets/01-telco/model_forest.rds")
model_forest <- readRDS("assets/01-telco/model_forest.rds")
```

```{r}
model_forest
```

Dari hasil yang diperoleh pada `model_forest`, didapatkan accuraci sebesar 0.78 dengan mtry sebanyak 2. Selanjutnya, akan dilakukan tuning model dengan melakukan upsample data. Artinya, kita akan membuat proporsi dari target variabel sama besar.
```{r}
up_train <- upSample(x = data_train[,-20],
                     y = data_train$Churn,
                     yname = "Churn")
```

Dilakukan pembuat model random forest dengan data upsample:
```{r}
set.seed(100)
# ctrl <- trainControl(method="repeatedcv", number=5, repeats=3)
# forest_upc <- train(Churn ~ ., data=up_train, method="rf", trControl = ctrl)
```

```{r}
#saveRDS(forest_upc,"assets/01-telco/model_caret.rds")
forest_upc <- readRDS("assets/01-telco/model_caret.rds")
```

Dari hasil model kedua diperoleh hasil sebagai berikut:
```{r}
forest_upc
```

Setelah dilakukan upsample data, terlihat nilai accuracy yang diperoleh lebih besar dibandingkan model sebelumnya sebesar 0.89 dengan mtry sebanyak 16. Selanjutnya, akan dilakukan prediksi terhadap `data_test`:

```{r}
pred <- predict(forest_upc,newdata = data_test,type = "prob")
pred$result <- as.factor(ifelse(pred$Yes > 0.45, "Yes","No"))
confusionMatrix(pred$result, data_test$Churn,positive = "Yes")
```

Pada kasus ini kita ingin memperoleh nila sensitivity/recall yang lebih besar, dengan menggunakan threshold sebesar 0.4 diperoleh nilai recall sebesar 0.70 dengan accuracy sebesar 0.79 dan precision sebesar 0.59. Dari model yang telah terbentuk kita dapat memperoleh nilai AUC pada model:
```{r}
library(ROCR)
pred_prob <- predict(object = forest_upc,newdata = data_test,type = "prob")
pred <-  prediction(pred_prob[,2],labels = data_test$Churn)
perf <- performance(prediction.obj = pred,measure = "tpr",x.measure = "fpr")
plot(perf)

```

```{r}
auc <- performance(pred,measure = "auc")
auc@y.values[[1]]
```

### Conclusion


```{r}
library(lime)
test_x <- data_test %>% 
  dplyr::select(-Churn)

explainer <- lime(test_x, forest_upc)
explanation <- lime::explain(test_x[1:2,],
                             explainer, 
                             labels = c("Yes"),
                             n_features = 8)

plot_features(explanation)
```

Setelah adanya model prediksi customer churn, pihak perusahaan telekomunikasi dapat dengan mudah mengetahui pelanggan yang memiliki kecendurungan akan churn. Kedua plot diatas memperlihatkan prediksi dua customer, kedua customer memiliki peluang besar untuk churn dan kita dapat mengetahui variabel mana yang `supports` dan `contradicts` terhadap hasil prediksi.